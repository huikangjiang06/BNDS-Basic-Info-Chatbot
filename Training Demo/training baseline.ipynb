{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fe5a1d-5d76-475d-95c6-6ee3c3255b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37307a93-5d3f-481e-ad24-fbb6e172ea0a",
   "metadata": {},
   "source": [
    "### 预处理 .txt 文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dac57ce-161e-4885-97ab-56dfabb3c166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_format_txt_files(folder_path):\n",
    "    \"\"\"\n",
    "    Reads all txt files from the given folder path, formats the content into prompts,\n",
    "    and stores them in a dictionary.\n",
    "\n",
    "    Args:\n",
    "    folder_path (str): The path to the folder containing the txt files.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary where keys are filenames and values are lists of formatted prompts.\n",
    "    \"\"\"\n",
    "    prompts_dict = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
    "                content = file.read()\n",
    "\n",
    "            sections = content.split('\\n\\n') \n",
    "            formatted_prompts = []\n",
    "\n",
    "            for section in sections:\n",
    "                if ':' in section:\n",
    "                    title, sentences = section.split(':', 1) # title: 小标题\n",
    "                    title = title.strip()\n",
    "                    sentences = sentences.strip().split('. ') # 按句让模型学习\n",
    "                    for sentence in sentences:\n",
    "                        if sentence:  # 确保非空\n",
    "                            prompt = f\"Please carefully read and remember the following facts about Beijing National Day School's {title} in {filename[:-4]}: \"\n",
    "                            prompt_length = len(prompt.split(\" \")) # 记录提示词长度，在Dataset里传给attention mask，之后在训练的时候避免模型学习提示词\n",
    "                            knowledege = prompt + sentence + \".\"\n",
    "                            prompt = prompt.replace(\"\\n\",\"\")\n",
    "                            formatted_prompts.append((knowledege,prompt_length)) # 以元组储存\n",
    "                else:\n",
    "                    sentences = section.strip().split('. ')\n",
    "                    for sentence in sentences:\n",
    "                        if sentence:  # Ensure the sentence is not empty\n",
    "                            prompt = f\"Please carefully read and remember the following facts about Beijing National Day School's {filename[:-4]}: \"\n",
    "                            prompt_length = len(prompt.split(\" \"))\n",
    "                            knowledege = prompt + sentence + \".\"\n",
    "                            prompt = prompt.replace(\"\\n\",\"\")\n",
    "                            formatted_prompts.append((knowledege,prompt_length))\n",
    "\n",
    "            prompts_dict[filename[:-4]] = formatted_prompts\n",
    "\n",
    "    return prompts_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23dc09-d246-4b06-8702-717544137a5a",
   "metadata": {},
   "source": [
    "### 加载模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd63f6f-7076-4b2b-80f6-5050be9a02cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeDataset(Dataset):\n",
    "    def __init__(self, prompt_dic, tokenizer, max_length=128):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.examples = []\n",
    "        \n",
    "        for _, knowledge_list in prompt_dic.items():\n",
    "            for (sentence, prompt_length) in knowledge_list:\n",
    "                encoding = tokenizer(\n",
    "                    sentence,\n",
    "                    max_length=max_length,\n",
    "                    padding=\"max_length\",\n",
    "                    truncation=True,\n",
    "                    return_tensors=\"pt\"\n",
    "                )\n",
    "\n",
    "                attention_mask = encoding['attention_mask'].flatten()\n",
    "                attention_mask[:prompt_length] = 0 # 把提示词部分的掩码设为0\n",
    "                \n",
    "                self.examples.append({\n",
    "                    'input_ids': encoding['input_ids'].flatten(),\n",
    "                    'attention_mask': attention_mask,\n",
    "                    'labels': encoding['input_ids'].flatten()\n",
    "                })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def train(model, dataloader, optimizer, num_epochs, device):\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        if epoch % 2 == 1:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ddf4f-e52e-42ce-8770-0601a78d3117",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/personal/知识库 - 格式化txt/' \n",
    "prompts_dict = read_and_format_txt_files(folder_path)\n",
    "for i, j in prompts_dict.items():\n",
    "    print(i, len(j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fa42d0-d9ce-46e3-93c9-492e1ba544fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('/personal/gpt2/')\n",
    "model = GPT2LMHeadModel.from_pretrained('/personal/gpt2/')\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'}) # gpt2没有默认设置padding\n",
    "    model.resize_token_embeddings(len(tokenizer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72b178-7704-4e75-b201-afff0f2bdbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练前示例\n",
    "with torch.no_grad():\n",
    "    encoding = tokenizer(\n",
    "        \"Tell me about Beijing National Day School's student housing conditions.\",\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "temperature = 0.7 \n",
    "top_k = 50  # 从top 50个候选词中选择\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=encoding[\"input_ids\"],\n",
    "    attention_mask=encoding[\"attention_mask\"],\n",
    "    max_new_tokens=100,\n",
    "    temperature=temperature,\n",
    "    top_k=top_k,\n",
    "    pad_token_id=tokenizer.eos_token_id, \n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(\n",
    "    outputs[0],\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f849c2-060a-4d62-9cda-48dc7d13897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KnowledgeDataset(prompts_dict, tokenizer, max_length=128)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ade772-0cff-40d5-ab8f-54f46dfbcd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, dataloader, optimizer, 10, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e247472-54cf-4ef8-9769-597d4e35c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练后实验\n",
    "with torch.no_grad():\n",
    "    encoding = tokenizer(\n",
    "        \"Beijing National Day School's theatre is located \",\n",
    "        max_length=128,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "temperature = 0.7 \n",
    "top_k = 100\n",
    "\n",
    "outputs = model.generate(\n",
    "    input_ids=encoding[\"input_ids\"].to('cuda'),\n",
    "    attention_mask=encoding[\"attention_mask\"].to('cuda'),\n",
    "    max_new_tokens=80,\n",
    "    temperature=temperature,\n",
    "    top_k=top_k,\n",
    "    pad_token_id=tokenizer.eos_token_id, \n",
    "    do_sample=True\n",
    ")\n",
    "\n",
    "generated_text = tokenizer.decode(\n",
    "    outputs[0],\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=True\n",
    ")\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb63483-68b8-454c-99c9-4cf08045b178",
   "metadata": {},
   "source": [
    "### 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fc2398-567d-41c4-9177-574a6d37d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def model_evaluation(model, df:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    获取模型表现，由F1-score，目标-预测相似度，提问-预测相关性构成。\n",
    "\n",
    "    参数：\n",
    "    model: 模型，用来计算参数量\n",
    "    df: 三列的DataFrame，第一列\"prompt\"，第二列\"truth\"，第三列\"prediction\"\n",
    "\n",
    "    输出：\n",
    "    score: 模型在数据上的平均得分\n",
    "    \"\"\"\n",
    "\n",
    "    sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def normalize_text(text):\n",
    "        \"\"\"文本标准化处理\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)  # 移除标点\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()  # 标准化空格\n",
    "        return text\n",
    "\n",
    "    def exact_match(pred:str, true:str):\n",
    "        \"\"\"精确匹配\"\"\"\n",
    "        pred_norm = normalize_text(pred)\n",
    "        true_norm = normalize_text(true)\n",
    "        return pred_norm == true_norm\n",
    "\n",
    "    def f1_score(pred:str, true:str):\n",
    "        \"\"\"F1分数\"\"\"\n",
    "        pred_tokens = set(normalize_text(pred).split())\n",
    "        true_tokens = set(normalize_text(true).split())\n",
    "        \n",
    "        if not pred_tokens or not true_tokens:\n",
    "            return 0.0\n",
    "        \n",
    "        common_tokens = pred_tokens & true_tokens\n",
    "        precision = len(common_tokens) / len(pred_tokens)\n",
    "        recall = len(common_tokens) / len(true_tokens)\n",
    "        \n",
    "        if precision + recall == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        return f1\n",
    "\n",
    "    \n",
    "    sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    \n",
    "    def truth_prediciton_similarity(pred:str, true:str):\n",
    "        \"\"\"目标与预测之间的语义相似度\"\"\"\n",
    "        pred_emb = sentence_transformer.encode([pred], convert_to_tensor=True)\n",
    "        true_emb = sentence_transformer.encode([true], convert_to_tensor=True)\n",
    "        cosine_sim = cosine_similarity(pred_emb, true_emb).item()\n",
    "        return cosine_sim\n",
    "\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    all_texts = df[\"prompt\"].tolist() + df[\"prediction\"].tolist()\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "\n",
    "    def prompt_prediciton_relavance(prompt:str,pred:str):\n",
    "        \"\"\"问题与预测之间的相关性\"\"\"\n",
    "        question_vector = vectorizer.transform([prompt])\n",
    "        answer_vector = vectorizer.transform([pred])\n",
    "        cosine_sim = cosine_similarity(question_vector, answer_vector)[0][0]\n",
    "        return cosine_sim\n",
    "\n",
    "    def model_parameter_score(model):\n",
    "        \"\"\"模型参数量评分\"\"\"\n",
    "        paramcount = model.paramcount\n",
    "        threshold = 1e9\n",
    "        if paramcount > threshold:\n",
    "            return -1\n",
    "        else:\n",
    "            return math.log(threshold - paramcount) / 9\n",
    "\n",
    "    total_score\n",
    "    for prompt, truth, pred in zip(df['prompt'],df['truth'],df['prediction']):\n",
    "        if exact_match(pred, truth):\n",
    "            total_score += 1\n",
    "        else:\n",
    "            F1 = f1_score(pred,truth)\n",
    "            TPsim = truth_prediciton_similarity(pred,truth)\n",
    "            PPrel = prompt_prediciton_relavance(pred,truth)\n",
    "            mps = model_parameter_score(model)\n",
    "            total_score += mps * ( F1 + TPsim + PPrel ) / 3\n",
    "\n",
    "    return total_score / len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
